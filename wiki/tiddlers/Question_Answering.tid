created: 20170405104624230
modified: 20180505063232797
tags: NLP
title: Question Answering
type: text/vnd.tiddlywiki

! Open Domain
* [[Reading Wikipedia to Answer Open-Domain Questions|https://arxiv.org/abs/1704.00051]]: Useful datasets and benchmarks provided

! Examples
* Machine Comprehension by Text-to-Text Neural Question Generation
* [[A Unified Query-based Generative Model for Question Generation and Question Answering|https://arxiv.org/abs/1709.01058]]
* [[Attention-based CNN Matching Net|https://arxiv.org/abs/1709.05036]]: a quite naive convolutional attention implementation for making choices

! SOTA
!! Seq2seq

* Encoder
** BiLSTM, read document $D$, generate augmented document sequence $\mathbf h^d$
** BiLSTM, read query $Q$ and subset $\mathbf h^d$, generate encoding $\mathbf h^q$ (original paper used answer as query so that words came from document)
** compute initial state for decoder
* Decoder
** Location, pointer network over document tokens, softmax $\mathbf\alpha$, compute context vector $\mathbf v$
** Shortlist, reads $\mathbf v$, softmax over answer vocabulary $\mathbf o$
** Source switching network (2-layer MLP) enables model to interpolate between these distributions

! Bibs

* [[DrQA]]
* [[R-Net]]
* [[QANet|https://github.com/NLPLearn/QANet]]: SOTA on SQuAD