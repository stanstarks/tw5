created: 20171117035730065
modified: 20181202092323707
tags: [[Inference Methods]]
title: Evolution Strategies
type: text/vnd.tiddlywiki

My $$f(\theta)$$ is easy to evaluate but hard to optimize, perhaps because it contains discrete operations, or the function is piecewhise constant. Backpropagation is not possible.

Observe that for any probability distribution $$p_\psi$$ over $$\theta$$ the following holds:
$$
\min_\theta f(\theta)\le\min_\psi\mathbb E_{\theta\sim p_\psi}f(\theta)
$$
therefore in ES we concentrate of the following optimization problem instead:
$$
\psi^*\rightarrow \arg\min_\psi\mathbb E_{\theta\sim p_\psi}f(\theta)
$$
Often, depending on the function $$f$$ and class of distribution $$p_\psi$$, a local minimum of $$f$$ can be recovered from a local minimum of $$\psi$$.

[[REINFORCE]] gradient estimator relies on the following trick
$$
\frac{\partial}{\partial \psi_i}\mathbb E_{\theta\sim p_\psi}[f(\theta)]=\mathbb E_{\theta\sim p_\psi}[\frac{\partial}{\partial \psi_i}\log p_\psi(\theta)f(\theta)]
$$

! Policy gradient methods for reinforcement learning with function approximation

* [[paper|https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf]]

! Refs

* [[JMLR14 Neural Evolution Strategies]]