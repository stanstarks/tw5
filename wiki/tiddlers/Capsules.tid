created: 20170918105144345
modified: 20180515035918921
tags: 
title: Capsules
type: text/vnd.tiddlywiki

! Bibs

* [[Dynamic Routing between Capsules|https://research.google.com/pubs/pub46351.html]]

! [[What is wrong with CNN|https://www.youtube.com/watch?v=Mqt8fs6ZbHk]]?

* Too few levels of structure
** Neurons, layers, whole nets666
** For example, we want to have a unit that can detect correlations between input
** Vector nonlinearity like softmax, analyse the covariance structure
* We need to group the neurons in each layer into "capsules" that do a lot of internal computation and then output a compact result
** A capsule is inspired by a mini-column

!! Capsule
Connection binding problem done in sequence.

Each capsule represents the presence and the instantiation parameters of a multi-dimensional entity of the type that the capsule detects. In the visual pathway, a capsule detects a particular type of object or object-part. It outputs 2 things:

* The probability that an object of that type is present
* The generalized pose of the object, includes position, orientation, scale, deformation, velocity, color etc.

Convnet problem

* feature extraction layers are interleaved with subsampling
* relationships between objects not trained
* the geometric view of vision is discarded

Map the percept to the initial hidden state of a deep recurrent neural net and train the RNN to output captions (without retraining the convnet)

! Computation
Routing-by-agreement: Each capsule makes a prediction for the parent capsule, which is then compared with the actual output. If the outputs matches, the coupling coefficient is increased. Let $u_i$ be an output of a capsule $i$, and $j$ be the parent capsule, the prediction is calculated as $u_{i|j} = W_{ij}u_i$. The coupling coefficient $c_{ij}$ is computed using softmax. Loss is high when entity is absent and capsule has high instantiation parameters.
$$
L_k = T_k\max(0, m^+-\|v^k\|)^2+\lambda(1-T_k)\max(0, \|v^k\| - m^-)^2
$$

! Remarks
* Capsule is like a convolutional Gaussian process? Can convolutional kernels capture covariance?
* Attention may not be good for high dimensional data